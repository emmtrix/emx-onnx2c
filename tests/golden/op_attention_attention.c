/*
 * Generated by emmtrix ONNX-to-C Code Generator (emx-onnx-cgen)
 *
 * Command line: n/a
 * Model checksum (sha256): 356d792e83c673d604776fc42bb785fd9699162499fb8c8ddbeb54646e097efa
 * Model name: model
 * Graph name: attention_graph
 * Inputs: 3 Outputs: 1 Nodes: 1 Initializers: 0
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: onnx2c (version: n/a)
 * Opset imports: ai.onnx=23
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stdint.h>
#include <math.h>

#ifndef idx_t
#define idx_t int32_t
#endif

/*
 * Node 0:
 * OpType: Attention
 * Name: n/a
 * Inputs: in0, in1, in2
 * Outputs: out
 * Attrs: n/a
 */
static inline void node0_attention(const float input_q[restrict 1][2][3][4], const float input_k[restrict 1][2][5][4], const float input_v[restrict 1][2][5][4], float output[restrict 1][2][3][4]) {
    const float scale = 0.5f;
    const float softcap = 0.0f;
    for (int b = 0; b < 1; ++b) {
        for (int h = 0; h < 2; ++h) {
            int kv_head = h / 1;
            for (int qi = 0; qi < 3; ++qi) {
                float scores[5];
                float max_score = -INFINITY;
                for (int ki = 0; ki < 5; ++ki) {
                    float score = 0.0f;
                    int k_index = ki - 0;
                    for (int d = 0; d < 4; ++d) {
                        float q_val;
                        float k_val;
                        q_val = input_q[b][h][qi][d];
                        k_val = input_k[b][kv_head][k_index][d];
                        score += q_val * k_val;
                    }
                    score *= scale;
                    float bias = 0.0f;
                    if (0 && ki > qi + 0) {
                        bias = -INFINITY;
                    }
                    float score_bias = score + bias;
                    float score_softcap = score_bias;
                    if (softcap != 0.0f) {
                        score_softcap = softcap * tanhf(score_bias / softcap);
                    }
                    scores[ki] = score_softcap;
                    if (score_softcap > max_score) {
                        max_score = score_softcap;
                    }
                }
                float weights[5];
                float sum = 0.0f;
                for (int ki = 0; ki < 5; ++ki) {
                    float weight = 0.0f;
                    if (max_score != -INFINITY) {
                        weight = expf(scores[ki] - max_score);
                    }
                    weights[ki] = weight;
                    sum += weight;
                }
                float inv_sum = sum == 0.0f ? 0.0f : (float)1.0f / sum;
                for (int vd = 0; vd < 4; ++vd) {
                    float acc = 0.0f;
                    for (int ki = 0; ki < 5; ++ki) {
                        float weight = weights[ki] * inv_sum;
                        acc += weight * input_v[b][kv_head][ki][vd];
                    }
                    output[b][h][qi][vd] = acc;
                }
            }
        }
    }
}

void model(const float in0[restrict 1][2][3][4], const float in1[restrict 1][2][5][4], const float in2[restrict 1][2][5][4], float out[restrict 1][2][3][4]) {
    node0_attention(in0, in1, in2, out);
}
