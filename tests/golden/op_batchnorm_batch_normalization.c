/*
 * Generated by emmtrix ONNX to C Compiler (emx-onnx2c)
 *
 * Command line: n/a
 * Model checksum (sha256): ea374829ef5f717d4e0f3a5368f05a822acbdc8dc140fc9fb7511c3cf1c0d5b0
 * Model name: model
 * Graph name: batchnorm_graph
 * Inputs: 1 Outputs: 1 Nodes: 1 Initializers: 4
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: onnx2c (version: n/a)
 * Opset imports: ai.onnx=13
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stddef.h>
#include <math.h>

static const float scale[3] = {
    1.0f, 1.5f, -0.5f
};

static const float bias[3] = {
    0.0f, 0.100000001f, -0.200000003f
};

static const float mean[3] = {
    0.5f, -0.5f, 1.0f
};

static const float var[3] = {
    0.25f, 0.5f, 1.5f
};

/*
 * Node 0:
 * OpType: BatchNormalization
 * Inputs: in0, scale, bias, mean, var
 * Outputs: out
 * Attrs:
 *   epsilon: 9.999999747378752e-06
 */
static inline void model_op0(const float in0[restrict 2][3][2][2], const float scale[restrict 3], const float bias[restrict 3], const float mean[restrict 3], const float var[restrict 3], float out[restrict 2][3][2][2]) {
    for (size_t i0 = 0; i0 < 2; ++i0) {
        for (size_t i1 = 0; i1 < 3; ++i1) {
            for (size_t i2 = 0; i2 < 2; ++i2) {
                for (size_t i3 = 0; i3 < 2; ++i3) {
                    size_t c = i1;
                    float denom = sqrtf(var[c] + 9.99999975e-06f);
                    out[i0][i1][i2][i3] = (in0[i0][i1][i2][i3] - mean[c]) / denom * scale[c] + bias[c];
                }
            }
        }
    }
}

void model(const float in0[restrict 2][3][2][2], float out[restrict 2][3][2][2]) {
    model_op0(in0, scale, bias, mean, var, out);
}
