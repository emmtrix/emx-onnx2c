/*
 * Generated by emmtrix ONNX to C Compiler (emx-onnx2c)
 *
 * Command line: n/a
 * Model checksum (sha256): f734b84cbea016998c7e4d598c21e6338c1ab479b9cbf9f1ae22b909228fd574
 * Model name: model
 * Graph name: softmax_graph
 * Inputs: 1 Outputs: 1 Nodes: 1 Initializers: 0
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: onnx2c (version: n/a)
 * Opset imports: ai.onnx=13
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stddef.h>
#include <math.h>

/*
 * Node 0:
 * OpType: Softmax
 * Inputs: in0
 * Outputs: out
 * Attrs:
 *   axis: 1
 */
static inline void model_op0(const float in0[restrict 2][3], float out[restrict 2][3]) {
    const float *input_flat = (const float *)in0;
    float *output_flat = (float *)out;
    const size_t outer = 2;
    const size_t axis_size = 3;
    const size_t inner = 1;
    for (size_t outer_idx = 0; outer_idx < outer; ++outer_idx) {
        for (size_t inner_idx = 0; inner_idx < inner; ++inner_idx) {
            size_t base = (outer_idx * axis_size * inner) + inner_idx;
            float max_value = input_flat[base];
            for (size_t axis_idx = 1; axis_idx < axis_size; ++axis_idx) {
                float value = input_flat[base + axis_idx * inner];
                if (value > max_value) {
                    max_value = value;
                }
            }
            float sum = 0;
            for (size_t axis_idx = 0; axis_idx < axis_size; ++axis_idx) {
                float value = expf(input_flat[base + axis_idx * inner] - max_value);
                output_flat[base + axis_idx * inner] = value;
                sum += value;
            }
            for (size_t axis_idx = 0; axis_idx < axis_size; ++axis_idx) {
                output_flat[base + axis_idx * inner] /= sum;
            }
        }
    }
}

void model(const float in0[restrict 2][3], float out[restrict 2][3]) {
    model_op0(in0, out);
}
