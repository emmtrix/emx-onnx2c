/*
 * Generated by emmtrix ONNX to C Compiler (emx-onnx2c)
 *
 * Command line: n/a
 * Model checksum (sha256): da0ce981b3953a1748ec00b37e11ea699f928427ec5b1c8c5daf595834f47d62
 * Model name: model
 * Graph name: layernormalization_graph
 * Inputs: 3 Outputs: 1 Nodes: 1 Initializers: 0
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: onnx2c (version: n/a)
 * Opset imports: ai.onnx=17
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stddef.h>
#include <math.h>

/*
 * Node 0:
 * OpType: LayerNormalization
 * Name: n/a
 * Inputs: in0, in1, in2
 * Outputs: out
 * Attrs:
 *   axis: 1
 *   epsilon: 9.999999747378752e-06
 */
static inline void node0_LayerNormalization(const float input0[restrict 2][3][4], const float scale[restrict 3][4], const float bias[restrict 3][4], float output[restrict 2][3][4]) {
    for (size_t i0 = 0; i0 < 2; ++i0) {
        float sum = 0.0f;
        for (size_t i1 = 0; i1 < 3; ++i1) {
            for (size_t i2 = 0; i2 < 4; ++i2) {
                sum += input0[i0][i1][i2];
            }
        }
        float mean = sum / 12;
        float var = 0.0f;
        for (size_t i1 = 0; i1 < 3; ++i1) {
            for (size_t i2 = 0; i2 < 4; ++i2) {
                float diff = input0[i0][i1][i2] - mean;
                var += diff * diff;
            }
        }
        var = var / 12;
        float inv_std = ((float)1) / sqrtf(var + 9.99999975e-06f);
        for (size_t i1 = 0; i1 < 3; ++i1) {
            for (size_t i2 = 0; i2 < 4; ++i2) {
                float value = (input0[i0][i1][i2] - mean) * inv_std;
                value = value * scale[i1][i2] + bias[i1][i2];
                output[i0][i1][i2] = value;
            }
        }
    }
}

void model(const float in0[restrict 2][3][4], const float in1[restrict 3][4], const float in2[restrict 3][4], float out[restrict 2][3][4]) {
    node0_LayerNormalization(in0, in1, in2, out);
}
