/*
 * Generated by emmtrix ONNX-to-C Code Generator (emx-onnx-cgen)
 *
 * Command line: n/a
 * Model checksum (sha256): c5a9b091eb151064739d10b0ae992ad4cad007f25c55aa31a733e0b0489be87d
 * Model name: model
 * Graph name: lpnormalization_graph
 * Inputs: 1 Outputs: 1 Nodes: 1 Initializers: 0
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: onnx2c (version: n/a)
 * Opset imports: ai.onnx=22
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stdint.h>
#include <math.h>

#ifndef idx_t
#define idx_t int32_t
#endif
#ifndef EMX_UNUSED
#if defined(__GNUC__) || defined(__clang__)
#define EMX_UNUSED __attribute__((unused))
#else
#define EMX_UNUSED
#endif
#endif

/*
 * Node 0:
 * OpType: LpNormalization
 * Name: n/a
 * Inputs: in0
 * Outputs: out
 * Attrs:
 *   axis: -1
 *   p: 1
 */
static inline void node0_lpnormalization(const float input0[2][3], float output[2][3]) {
    const float *input_flat = (const float *)input0;
    float *output_flat = (float *)output;
    const idx_t outer = 2;
    const idx_t axis_size = 3;
    const idx_t inner = 1;
    for (idx_t outer_idx = 0; outer_idx < outer; ++outer_idx) {
        for (idx_t inner_idx = 0; inner_idx < inner; ++inner_idx) {
            idx_t base = (outer_idx * axis_size * inner) + inner_idx;
            float acc = 0.0f;
            for (idx_t axis_idx = 0; axis_idx < axis_size; ++axis_idx) {
                float value = input_flat[base + axis_idx * inner];
                acc += fabsf(value);
            }
            for (idx_t axis_idx = 0; axis_idx < axis_size; ++axis_idx) {
                output_flat[base + axis_idx * inner] = input_flat[base + axis_idx * inner] / acc;
            }
        }
    }
}

_Bool model_load(const char *path) {
    (void)path;
    return 1;
}

void model(const float in0[restrict 2][3], float out[restrict 2][3]) {
    node0_lpnormalization(in0, out);
}
